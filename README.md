# rag-local-llm
rag-local-llm-cpu runs Retrieval-Augmented Generation (RAG) models on local machines using only CPU resources. It combines a large language model (LLM) with a retrieval system for context-aware text generation, ideal for offline apps where privacy and efficiency are key, without needing cloud infrastructure or GPUs.
